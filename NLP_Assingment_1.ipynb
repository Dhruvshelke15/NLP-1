{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69f1131-6b21-4cd1-80d2-c7f6ec8a1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba24a96-fcb5-4d09-846d-cfbbb5a72120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Data Preprocessing ---\n",
    "class Corpus:\n",
    "    def __init__(self, train_path, val_path, unk_threshold=1):\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.unk_threshold = unk_threshold\n",
    "        \n",
    "        self.vocab = set()\n",
    "        self.train_corpus_unk = []\n",
    "        self.val_corpus_unk = []\n",
    "\n",
    "    def load_and_prepare_data(self):\n",
    "        print(\"Loading and preparing data...\")\n",
    "        # 1. Load and tokenize sentences from the file\n",
    "        raw_train_corpus = self._preprocess_file(self.train_path)\n",
    "        raw_val_corpus = self._preprocess_file(self.val_path)\n",
    "\n",
    "        # 2. Create vocabulary from training data and handle <UNK> tokens\n",
    "        self.vocab, self.train_corpus_unk = self._handle_unknowns(raw_train_corpus)\n",
    "\n",
    "        # 3. Replace words in validation data with <UNK> based on the created vocabulary\n",
    "        self.val_corpus_unk = self._replace_oov(raw_val_corpus, self.vocab)\n",
    "        print(\"Data preparation complete.\")\n",
    "\n",
    "    def _preprocess_file(self, file_path):\n",
    "        processed_sentences = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                tokens = line.lower().strip().split()\n",
    "                if tokens:\n",
    "                    processed_sentences.append(['<s>'] + tokens + ['</s>'])\n",
    "        return processed_sentences\n",
    "\n",
    "    def _handle_unknowns(self, corpus):\n",
    "        # Counts word frequencies and replaces words below a threshold with <UNK>.\n",
    "        # Count the frequency of all words\n",
    "        word_counts = Counter(word for sentence in corpus for word in sentence)\n",
    "\n",
    "        # Add only words with a frequency greater than the threshold to the vocabulary dictionary.\n",
    "        vocab = {word for word, count in word_counts.items() if count > self.unk_threshold}\n",
    "        vocab.update(['<s>', '</s>', '<UNK>'])\n",
    "        \n",
    "        processed_corpus = [[word if word in vocab else '<UNK>' for word in sentence] for sentence in corpus]\n",
    "        return vocab, processed_corpus\n",
    "    \n",
    "    def _replace_oov(self, corpus, vocab):\n",
    "        # Replaces words not in the vocabulary with <UNK>.\n",
    "        return [[word if word in vocab else '<UNK>' for word in sentence] for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aaba93-f7a8-44e6-b0ce-deb4dad55ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. N-gram Language Model Class (based on your provided logic) ---\n",
    "\n",
    "class NgramLanguageModel:\n",
    "    def __init__(self, n=1, k=0):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.unigram_counts = Counter()\n",
    "        self.bigram_counts = Counter()\n",
    "        self.total_tokens = 0\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def train(self, corpus):\n",
    "        \"\"\"Trains the language model on the given corpus.\"\"\"\n",
    "        # print(\"Training model...\")\n",
    "        for sentence in corpus:\n",
    "            self.total_tokens += len(sentence)\n",
    "            # --- Unigram Counts ---\n",
    "            for word in sentence:\n",
    "                self.unigram_counts[word] += 1\n",
    "\n",
    "            # --- Bigram Counts ---\n",
    "            if self.n >= 2:\n",
    "                for i in range(len(sentence) - 1):\n",
    "                    bigram = (sentence[i], sentence[i+1])\n",
    "                    self.bigram_counts[bigram] += 1\n",
    "        \n",
    "        self.vocab_size = len(self.unigram_counts)\n",
    "        # print(f\"Training complete. Vocabulary size: {self.vocab_size}\")\n",
    "\n",
    "    def get_smoothed_unigram_prob(self, word):\n",
    "        \"\"\"Calculates smoothed unigram probability.\"\"\"\n",
    "        numerator = self.unigram_counts.get(word, 0) + self.k\n",
    "        denominator = self.total_tokens + (self.k * self.vocab_size)\n",
    "        return numerator / denominator\n",
    "\n",
    "    def get_smoothed_bigram_prob(self, prev_word, word):\n",
    "        \"\"\"Calculates Add-k smoothed bigram probability.\"\"\"\n",
    "        bigram = (prev_word, word)\n",
    "        numerator = self.bigram_counts.get(bigram, 0) + self.k\n",
    "        denominator = self.unigram_counts.get(prev_word, 0) + (self.k * self.vocab_size)\n",
    "        # Handle case where the context (prev_word) was never seen\n",
    "        if denominator == 0:\n",
    "            return 1 / self.vocab_size\n",
    "        return numerator / denominator\n",
    "    \n",
    "    def calculate_perplexity(self, validation_corpus):\n",
    "        \"\"\"Calculates perplexity for a unigram model.\"\"\"\n",
    "        total_log_prob = 0.0\n",
    "        # M is the number of words / m is the number of sentences\n",
    "        M = 0\n",
    "\n",
    "        for sentence in validation_corpus:\n",
    "            # Total tokens in validation set, excluding <s> start tokens\n",
    "            M += len(sentence) - 1\n",
    "            for i in range(1, len(sentence)):\n",
    "                if self.n == 1 :\n",
    "                    word = sentence[i]\n",
    "                    prob = self.get_smoothed_unigram_prob(word)\n",
    "\n",
    "                if self.n == 2 :\n",
    "                    prev_word = sentence[i-1]\n",
    "                    word = sentence[i]\n",
    "                    prob = self.get_smoothed_bigram_prob(prev_word, word)\n",
    "                    \n",
    "                if prob > 0:\n",
    "                    total_log_prob += math.log2(prob)\n",
    "                else:\n",
    "                    total_log_prob += math.log2(1e-10)\n",
    "                \n",
    "\n",
    "        if M == 0:\n",
    "            return float('inf')\n",
    "                    \n",
    "        l = total_log_prob / M\n",
    "        perplexity = 2 ** (-l)\n",
    "        return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab8cec91-6ec7-420a-9b99-77749b29110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution Code ---\n",
    "train_path = 'train.txt'\n",
    "val_path = 'val.txt'\n",
    "\n",
    "corpus = Corpus(train_path, val_path, unk_threshold = 1)\n",
    "corpus.load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9c1ab-bedc-4cf1-b04b-0162591641f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vec = [1, 2]\n",
    "k_vec = [1, 0.1, 0.01, 0.001, 0]\n",
    "\n",
    "results_train = np.zeros((len(n_vec) * len(k_vec), 3), dtype=float)\n",
    "idx = 0\n",
    "for n in n_vec:\n",
    "    for k in k_vec:\n",
    "        model = NgramLanguageModel(n=n, k=k)\n",
    "        model.train(corpus.train_corpus_unk)\n",
    "        ppl = model.calculate_perplexity(corpus.train_corpus_unk)\n",
    "        \n",
    "        results_train[idx] = [n, k, ppl]\n",
    "        idx += 1\n",
    "\n",
    "results_val = np.zeros((len(n_vec) * len(k_vec), 3), dtype=float)\n",
    "idx = 0\n",
    "for n in n_vec:\n",
    "    for k in k_vec:\n",
    "        model = NgramLanguageModel(n=n, k=k)\n",
    "        model.train(corpus.train_corpus_unk)\n",
    "        ppl = model.calculate_perplexity(corpus.val_corpus_unk)\n",
    "        \n",
    "        results_val[idx] = [n, k, ppl]\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f82a5f-f4cd-435b-9fd8-e3b4e74e347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## LANGUAGE MODEL PERPLEXITY EVALUATION ##\")\n",
    "print(\"--- MODEL TRAINING SET EVALUATION ---\")\n",
    "print(\"--- Perplexity on Training Set ---\")\n",
    "\n",
    "for row in results_train :\n",
    "    if row[0] == 1 :\n",
    "        print(f\"Unigram | k = {row[1]:<6.3f} | Perplexity: {row[2]:.4f}\")    \n",
    "    if row[0] == 2 :\n",
    "        print(f\"Bigram  | k = {row[1]:<6.3f} | Perplexity: {row[2]:.4f}\")    \n",
    "\n",
    "print(\"\\n--- Perplexity on Validation Set ---\")\n",
    "for row in results_val :\n",
    "    if row[0] == 1 :\n",
    "        print(f\"Unigram | k = {row[1]:<6.3f} | Perplexity: {row[2]:.4f}\")    \n",
    "    if row[0] == 2 :\n",
    "        print(f\"Bigram  | k = {row[1]:<6.3f} | Perplexity: {row[2]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a78bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## LANGUAGE MODEL PERPLEXITY EVALUATION ##\n",
      "--- MODEL TRAINING SET EVALUATION ---\n",
      "--- Perplexity on Training Set ---\n",
      "Unigram Perplexity: 336.5974, k = 1\n",
      "Unigram Perplexity: 335.6611, k = 0.1\n",
      "Unigram Perplexity: 335.6542, k = 0.01\n",
      "Unigram Perplexity: 335.6547, k = 0.001\n",
      "Unigram Perplexity: 335.6547, k = 0\n",
      "Bigram Perplexity: 380.1728, k = 1\n",
      "Bigram Perplexity: 108.1736, k = 0.1\n",
      "Bigram Perplexity: 49.1018, k = 0.01\n",
      "Bigram Perplexity: 35.8265, k = 0.001\n",
      "Bigram Perplexity: 33.0065, k = 0\n",
      "--- Perplexity on Validation Set ---\n",
      "Perplexity on Validation Set\n",
      "Unigram Perplexity: 295.4775, k = 1\n",
      "Unigram Perplexity: 293.3962, k = 0.1\n",
      "Unigram Perplexity: 293.2443, k = 0.01\n",
      "Unigram Perplexity: 293.2298, k = 0.001\n",
      "Unigram Perplexity: 293.2282, k = 0\n",
      "Bigram Perplexity: 429.0841, k = 1\n",
      "Bigram Perplexity: 185.0601, k = 0.1\n",
      "Bigram Perplexity: 142.0454, k = 0.01\n",
      "Bigram Perplexity: 175.9258, k = 0.001\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m model = NgramLanguageModel(n = n, k = k)\n\u001b[32m     27\u001b[39m model.train(corpus.train_corpus_unk)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m ppl = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval_corpus_unk\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m1\u001b[39m :\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnigram Perplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, k = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mNgramLanguageModel.calculate_perplexity\u001b[39m\u001b[34m(self, validation_corpus)\u001b[39m\n\u001b[32m     66\u001b[39m             total_log_prob += math.log2(prob)\n\u001b[32m     67\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m             total_log_prob += \u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1e-1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m M == \u001b[32m0\u001b[39m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: math domain error"
     ]
    }
   ],
   "source": [
    "n_vec = [1, 2]\n",
    "k_vec = [1, 0.1, 0.01, 0.001, 0]\n",
    "\n",
    "print(\"## LANGUAGE MODEL PERPLEXITY EVALUATION ##\")\n",
    "print(\"--- MODEL TRAINING SET EVALUATION ---\")\n",
    "print(\"--- Perplexity on Training Set ---\")\n",
    "\n",
    "# Print the results for each models\n",
    "for n in n_vec:\n",
    "    for k in k_vec:\n",
    "        model = NgramLanguageModel(n = n, k = k)\n",
    "        model.train(corpus.train_corpus_unk)\n",
    "        ppl = model.calculate_perplexity(corpus.train_corpus_unk)    \n",
    "        \n",
    "        if n == 1 :\n",
    "            print(f\"Unigram Perplexity: {ppl:.4f}, k = {k}\")\n",
    "        if n == 2 :\n",
    "            print(f\"Bigram Perplexity: {ppl:.4f}, k = {k}\")\n",
    "\n",
    "print(\"--- Perplexity on Validation Set ---\")\n",
    "\n",
    "# Print the results for each models\n",
    "print(f\"Perplexity on Validation Set\")\n",
    "for n in n_vec:\n",
    "    for k in k_vec:\n",
    "        model = NgramLanguageModel(n = n, k = k)\n",
    "        model.train(corpus.train_corpus_unk)\n",
    "        ppl = model.calculate_perplexity(corpus.val_corpus_unk)    \n",
    "        \n",
    "        if n == 1 :\n",
    "            print(f\"Unigram Perplexity: {ppl:.4f}, k = {k}\")\n",
    "        if n == 2 :\n",
    "            print(f\"Bigram Perplexity: {ppl:.4f}, k = {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030e6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
